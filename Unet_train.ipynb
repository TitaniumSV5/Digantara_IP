{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vnzYJPSlUwu6",
        "outputId": "9ed467b2-b1bd-4425-c667-15c728a7c4a6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting roboflow\n",
            "  Downloading roboflow-1.1.63-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from roboflow) (2025.4.26)\n",
            "Collecting idna==3.7 (from roboflow)\n",
            "  Downloading idna-3.7-py3-none-any.whl.metadata (9.9 kB)\n",
            "Requirement already satisfied: cycler in /usr/local/lib/python3.11/dist-packages (from roboflow) (0.12.1)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.4.8)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from roboflow) (3.10.0)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.0.2)\n",
            "Collecting opencv-python-headless==4.10.0.84 (from roboflow)\n",
            "  Downloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: Pillow>=7.1.2 in /usr/local/lib/python3.11/dist-packages (from roboflow) (11.2.1)\n",
            "Collecting pillow-heif>=0.18.0 (from roboflow)\n",
            "  Downloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.9.0.post0)\n",
            "Collecting python-dotenv (from roboflow)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.32.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.17.0)\n",
            "Requirement already satisfied: urllib3>=1.26.6 in /usr/local/lib/python3.11/dist-packages (from roboflow) (2.4.0)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.11/dist-packages (from roboflow) (4.67.1)\n",
            "Requirement already satisfied: PyYAML>=5.3.1 in /usr/local/lib/python3.11/dist-packages (from roboflow) (6.0.2)\n",
            "Requirement already satisfied: requests-toolbelt in /usr/local/lib/python3.11/dist-packages (from roboflow) (1.0.0)\n",
            "Collecting filetype (from roboflow)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (1.3.2)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (4.57.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->roboflow) (3.2.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->roboflow) (3.4.1)\n",
            "Downloading roboflow-1.1.63-py3-none-any.whl (85 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.3/85.3 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.7-py3-none-any.whl (66 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading opencv_python_headless-4.10.0.84-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow_heif-0.22.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m46.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: filetype, python-dotenv, pillow-heif, opencv-python-headless, idna, roboflow\n",
            "  Attempting uninstall: opencv-python-headless\n",
            "    Found existing installation: opencv-python-headless 4.11.0.86\n",
            "    Uninstalling opencv-python-headless-4.11.0.86:\n",
            "      Successfully uninstalled opencv-python-headless-4.11.0.86\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "Successfully installed filetype-1.2.0 idna-3.7 opencv-python-headless-4.10.0.84 pillow-heif-0.22.0 python-dotenv-1.1.0 roboflow-1.1.63\n",
            "loading Roboflow workspace...\n",
            "loading Roboflow project...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading Dataset Version Zip in SSA-Annotation-6 to coco-segmentation:: 100%|██████████| 33028/33028 [00:00<00:00, 34376.15it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\n",
            "Extracting Dataset Version Zip to SSA-Annotation-6 in coco-segmentation:: 100%|██████████| 85/85 [00:00<00:00, 709.85it/s]\n"
          ]
        }
      ],
      "source": [
        "# Roboflow API for dataset retrieval\n",
        "\n",
        "!pip install roboflow\n",
        "\n",
        "from roboflow import Roboflow\n",
        "rf = Roboflow(api_key=\"uVOAXSWN9rfXjBxgvL5W\")\n",
        "project = rf.workspace(\"titaniumsv5\").project(\"ssa-annotation\")\n",
        "version = project.version(6)\n",
        "dataset = version.download(\"coco-segmentation\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FHpzNc4tYs-v",
        "outputId": "e84a8560-2173-4651-a546-3389f55095e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (2.0.8)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pycocotools) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "pip install pycocotools opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZ0PPmGOZFsa",
        "outputId": "0074b5a4-6207-46cc-f736-e9c50e3ed5c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "_annotations.coco.json\n",
            "img_adjusted_Raw_Observation_004_Set1_png.rf.b27b3221d82ae9165b4b635351134e93.jpg\n",
            "img_adjusted_Raw_Observation_005_Set1_png.rf.a0c6c601d292cc1341b8fd75700b009f.jpg\n",
            "img_adjusted_Raw_Observation_010_Set1_png.rf.bf72c59d596abbd60f39527a5701c2bd.jpg\n",
            "img_adjusted_Raw_Observation_011_Set1_png.rf.f65db8188bac8789889801ceb947d0e8.jpg\n",
            "img_adjusted_Raw_Observation_013_Set2_png.rf.466ea8b1fa305b477cdda5b7128a53e4.jpg\n",
            "img_adjusted_Raw_Observation_021_Set2_png.rf.6067dd87aa6967dee7a369722dcc0a6e.jpg\n",
            "img_adjusted_Raw_Observation_026_Set3_png.rf.9fe188f9a48c00ea23fcc03b47a79fd6.jpg\n",
            "img_adjusted_Raw_Observation_029_Set3_png.rf.099e49918eed5baa232a5fed736abbe8.jpg\n",
            "img_adjusted_Raw_Observation_031_Set3_png.rf.526bd807285b63a719da265bca3618f4.jpg\n",
            "img_adjusted_Raw_Observation_032_Set3_png.rf.01e0ef3fa4abcdfc153f6ee5cacdcd59.jpg\n"
          ]
        }
      ],
      "source": [
        "!ls /content/SSA-Annotation-6/valid/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GOGkWo7Gcba_"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "\n",
        "# Image transformation\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),   \n",
        "    transforms.ToTensor(),    \n",
        "])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87e9holBYwKS",
        "outputId": "a53ce307-d829-41c6-8cab-52d1fd50f7d2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pycocotools in /usr/local/lib/python3.11/dist-packages (2.0.8)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: matplotlib>=2.1.0 in /usr/local/lib/python3.11/dist-packages (from pycocotools) (3.10.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pycocotools) (2.0.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.3.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (4.57.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (11.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (3.2.3)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib>=2.1.0->pycocotools) (2.9.0.post0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib>=2.1.0->pycocotools) (1.17.0)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchvision import transforms\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "# Dataset (COCO segmentation format)\n",
        "class CocoSegmentationDataset(Dataset):\n",
        "    def __init__(self, image_dir, annotation_file, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.transform = transform\n",
        "        self.coco = COCO(annotation_file)\n",
        "        self.image_ids = list(self.coco.imgs.keys())\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_ids)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "      img_id = self.image_ids[idx]\n",
        "      img_info = self.coco.loadImgs(img_id)[0]\n",
        "      img_path = os.path.join(self.image_dir, img_info['file_name'])\n",
        "\n",
        "      image = cv2.imread(img_path)\n",
        "      image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "      image = Image.fromarray(image)\n",
        "\n",
        "    # Creating mask\n",
        "      ann_ids = self.coco.getAnnIds(imgIds=img_id)\n",
        "      anns = self.coco.loadAnns(ann_ids)\n",
        "      mask = np.zeros((img_info['height'], img_info['width']), dtype=np.uint8)\n",
        "      for ann in anns:\n",
        "        mask = np.maximum(mask, self.coco.annToMask(ann))\n",
        "\n",
        "      if self.transform:\n",
        "        image = self.transform(image)\n",
        "\n",
        "    # Transforming mask manually\n",
        "      mask = cv2.resize(mask, (image.shape[2], image.shape[1]))\n",
        "      mask = torch.from_numpy(mask).float().unsqueeze(0) / 255.0\n",
        "\n",
        "      return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_OitcEZckhZ",
        "outputId": "8331acc2-ccc7-47f9-dca1-bf0786c7117e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.02s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "# Loading training dataset and creating a DataLoader for batching and shuffling\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "train_dataset = CocoSegmentationDataset(\n",
        "    image_dir=\"/content/SSA-Annotation-6/train\",\n",
        "    annotation_file=\"/content/SSA-Annotation-6/train/_annotations.coco.json\",\n",
        "    transform=transform\n",
        ")\n",
        "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tRGpRjUuaVoB",
        "outputId": "96541a16-129e-4bed-f896-df4a5990884a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch [1/20], Loss: 1.0354\n",
            "Epoch [2/20], Loss: 1.0098\n",
            "Epoch [3/20], Loss: 0.8309\n",
            "Epoch [4/20], Loss: 0.0276\n",
            "Epoch [5/20], Loss: 0.0000\n",
            "Epoch [6/20], Loss: 0.0000\n",
            "Epoch [7/20], Loss: 0.0000\n",
            "Epoch [8/20], Loss: 0.0000\n",
            "Epoch [9/20], Loss: 0.0000\n",
            "Epoch [10/20], Loss: 0.0000\n",
            "Epoch [11/20], Loss: 0.0000\n",
            "Epoch [12/20], Loss: 0.0000\n",
            "Epoch [13/20], Loss: 0.0000\n",
            "Epoch [14/20], Loss: 0.0000\n",
            "Epoch [15/20], Loss: 0.0000\n",
            "Epoch [16/20], Loss: 0.0000\n",
            "Epoch [17/20], Loss: 0.0000\n",
            "Epoch [18/20], Loss: 0.0000\n",
            "Epoch [19/20], Loss: 0.0000\n",
            "Epoch [20/20], Loss: 0.0000\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "\n",
        "# Basic UNet architecture for image segmentation\n",
        "\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(UNet, self).__init__()\n",
        "        \n",
        "        # Encoder blocks for downsampling path (Input/Output)\n",
        "        self.enc1 = self.contract_block(3, 64)\n",
        "        self.enc2 = self.contract_block(64, 128)\n",
        "        self.enc3 = self.contract_block(128, 256)\n",
        "\n",
        "        # Bottleneck block for lowest paart of network\n",
        "        self.bottleneck = self.double_conv(256, 512)\n",
        "\n",
        "        # Decoder blocks for upsampling path\n",
        "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
        "        self.dec3 = self.double_conv(256 + 128, 256)\n",
        "\n",
        "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
        "        self.dec2 = self.double_conv(128 + 64, 128)\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
        "        self.dec1 = self.double_conv(64, 64)\n",
        "\n",
        "        # Final convolution layer\n",
        "        self.final_conv = nn.Conv2d(64, num_classes, kernel_size=1)\n",
        "\n",
        "    # Contracting block for downsampling path\n",
        "    def contract_block(self, in_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "\n",
        "    # Double conv block, no downsampling\n",
        "    def double_conv(self, in_channels, out_channels):\n",
        "        return nn.Sequential(\n",
        "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        enc1 = self.enc1(x)\n",
        "        enc2 = self.enc2(enc1)\n",
        "        enc3 = self.enc3(enc2)\n",
        "\n",
        "        bottleneck = self.bottleneck(enc3)\n",
        "\n",
        "        up3 = self.up3(bottleneck)\n",
        "        dec3 = self.dec3(torch.cat([up3, enc2], dim=1))\n",
        "\n",
        "        up2 = self.up2(dec3)\n",
        "        dec2 = self.dec2(torch.cat([up2, enc1], dim=1))\n",
        "\n",
        "        up1 = self.up1(dec2)\n",
        "        dec1 = self.dec1(up1)\n",
        "\n",
        "        return self.final_conv(dec1)\n",
        "\n",
        "\n",
        "# Model training loop\n",
        "\n",
        "num_classes = 2\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = UNet(num_classes=num_classes).to(device)\n",
        "\n",
        "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "criterion = nn.CrossEntropyLoss() \n",
        "\n",
        "num_epochs = 20\n",
        "\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for images, masks in train_loader:\n",
        "        images = images.to(device)                  \n",
        "        masks = masks.to(device).long().squeeze(1)  \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)                      \n",
        "        loss = criterion(outputs, masks)   \n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "\n",
        "    avg_loss = running_loss / len(train_loader)\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U0FxkQSPhuRC",
        "outputId": "268b3699-a5fe-4e10-b6e2-ef0663a6bbad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "loading annotations into memory...\n",
            "Done (t=0.00s)\n",
            "creating index...\n",
            "index created!\n"
          ]
        }
      ],
      "source": [
        "# Define transform for validation dataset (same as training)\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((128, 128)),\n",
        "    transforms.ToTensor(),\n",
        "])\n",
        "\n",
        "val_dataset = CocoSegmentationDataset(\n",
        "    image_dir=\"/content/SSA-Annotation-6/valid\", \n",
        "    annotation_file=\"/content/SSA-Annotation-6/valid/_annotations.coco.json\",\n",
        "    transform=transform\n",
        ")\n",
        "\n",
        "validation_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
